Hereâ€™s your **final cleaned README** â€” you can copy-paste it directly into your `README.md` file on GitHub.

````markdown
# ğŸ¤– RAG-Powered Document Chatbot (PDF, Word & More)

A **Retrieval-Augmented Generation (RAG)** chatbot built with **LangChain**, **FAISS**, **HuggingFace embeddings**, and **Ollama**.  
It allows you to **chat with your own documents** (PDF, DOCX, TXT) by creating a searchable vector database and retrieving relevant chunks to answer your questions.

---

## âœ¨ Features
- ğŸ“‚ Upload **PDF, DOCX, and TXT** documents
- ğŸ” Automatically **split text into chunks** for better search
- ğŸ“š Store document embeddings in a **FAISS vector database**
- ğŸ’¬ Use **Ollama LLM** (DeepSeek R1 model) for answering questions
- ğŸ›  **Custom Prompt Template** for concise answers (â‰¤ 250 words)
- âš¡ Quick and interactive **Streamlit** UI

---

## ğŸ›  Installation

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-username/document-chatbot.git
cd document-chatbot
````

### 2ï¸âƒ£ Install Dependencies

Make sure you have **Python 3.9+** installed.

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Install Ollama & Model

* Download and install [Ollama](https://ollama.ai/download)
* Pull the DeepSeek R1 model:

```bash
ollama pull deepseek-r1:1.5b
```

---

## ğŸš€ Usage

### 1ï¸âƒ£ Run the Streamlit App

```bash
streamlit run app.py
```

### 2ï¸âƒ£ Upload Documents

* Supported formats: `.pdf`, `.docx`, `.txt`
* Multiple files can be uploaded at once.

### 3ï¸âƒ£ Create Vector Store

* Go to the **sidebar** and click **"Create / Update Vector Store"** to process your documents.

### 4ï¸âƒ£ Ask Questions

* Type your question in the text box and click **"Get Answer"**
* The bot will search relevant chunks and generate an answer.

---

## ğŸ“‚ Project Structure

```
ğŸ“ data/                 # Uploaded documents (auto-created)
ğŸ“ faiss_index/          # Vector store (auto-created)
app.py                   # Main Streamlit app
requirements.txt         # Python dependencies
README.md                # Project documentation
```

---

## âš™ï¸ Configuration

* **Embeddings Model:** `all-MiniLM-L6-v2` (HuggingFace)
* **LLM Model:** `deepseek-r1:1.5b` (Ollama)
* **Chunk Size:** 1000 characters (with 100 overlap)
* **Search Top-K:** 3 chunks

---

## ğŸ“Œ Requirements

* Python 3.9+
* Streamlit
* LangChain
* HuggingFace Embeddings
* FAISS
* Ollama (with DeepSeek model)

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€”
âœ… You can use it freely
âœ… You can modify it
âœ… You can share it (even for commercial purposes)
ğŸ“Œ Just keep the original license and give credit to the author.

---

## ğŸ’¡ Future Improvements

* âœ… Add chat history memory
* âœ… Support for more file formats (CSV, HTML, Markdown)
* âœ… Deploy on cloud platforms like **Streamlit Community Cloud** or **Hugging Face Spaces**

---

ğŸ’™ **Contributions are welcome!** Fork the repo and submit a pull request.

```

Do you want me to **also make a ready `requirements.txt`** so that people can run your chatbot with just one command? That will make your GitHub project complete.
```

